#base path
#PC
#base_path_project <- "C:\\Users\\zbush\\Documents\\GitHub\\credit-fraud-detection\\"
#base_path_data <- "C:\\Users\\zbush\\Documents\\GitHub\\Data\\"
#mac
base_path_project <- "//Users//zachbushby//Documents//edu//data_science//Projects//Credit Fraud Detection//"
base_path_data <- "//Users//zachbushby//Documents//edu//data_science//Projects//Data//Credit Fraud Detection//"
#installs and loads any libraries not already installed and loaded
#loads all training and testing datasets
source(paste0(base_path_project,"1. Load Data_Libraries//1. Libraries.R"))
#download all train + test datasets (scaled and balanced data)
#source(paste0(base_path_project,"2. Cleaning//2. Cleaning.R"))
#loads all training + testing datasets
source(paste0(base_path_project,"4. Modelling//4.1 Train_Test_Data.R"))
#Does all comparisons
source(paste0(base_path_project,"4. Modelling//4. Comparison.R"))
#results:
tables[["Near Miss"]]
tables[["SMOTE"]]
tables[["Tomek Links"]]
#threhold optimisation
preds <- list(
nearmiss = nearmiss_log_pred,
smote = smote_log_pred,
tomek = tomek_log_pred)
for (pred_name in names(preds)){
#function to calculate precision, recall, and F1 score for a given threshold
calc_metrics <- function(threshold, predictions, actuals) {
pred_binary <- ifelse(predictions > threshold, 1, 0)
cm <- confusionMatrix(as.factor(pred_binary), as.factor(actuals))
precision <- cm$byClass['Precision']
recall <- cm$byClass['Recall']
f1_score <- cm$byClass['F1']
return(c(Threshold = threshold, Precision = precision, Recall = recall, F1 = f1_score))
}
#iterate through different thresholds
thresholds <- seq(0.1, 0.9, by = 0.01)
metrics <- t(sapply(thresholds, function(t) calc_metrics(t, preds[[pred_name]], test_data$Class)))
metrics_df <- as.data.frame(metrics)
#optimal threshold = highest F1 score as f1 takes into account both recall and precision
optimal_row <- metrics_df[which.max(metrics_df$F1), ]
optimal_threshold <- optimal_row$Threshold
print(pred_name)
print(optimal_row)
}
#Does all comparisons
source(paste0(base_path_project,"4. Modelling//4. Comparison.R"))
actual <- test_data$Class
nearmiss_confusionmatrices <- list(
`Logistic Regression` = nearmiss_log_cmatrix,
`QDA` = nearmiss_qda_cmatrix,
`LDA` = nearmiss_lda_cmatrix,
`KNN` = nearmiss_knn_cmatrix,
`Random Forest` = nearmiss_rf_cmatrix,
`Linear SVM` = nearmiss_linear_svm_cmatrix,
`Poly SVM` = nearmiss_poly_svm_cmatrix,
`Radial SVM` = nearmiss_radial_svm_cmatrix,
`Naive Bayes` = nearmiss_nb_cmatrix,
`GBM` = nearmiss_gbm_cmatrix,
`XGBoost` = nearmiss_xgb_cmatrix,
`Single Neural Net` = nearmiss_single_nn_cmatrix,
`2 layer Neural Net` = nearmiss_two_nn_cmatrix,
`Deep Neural Net` = nearmiss_deep_nn_cmatrix
)
smote_confusionmatrices <- list(
`Logistic Regression` = smote_log_cmatrix,
`QDA` = smote_qda_cmatrix,
`LDA` = smote_lda_cmatrix,
`Random Forest` = smote_rf_cmatrix,
`Naive Bayes` = smote_nb_cmatrix,
`GBM` = smote_gbm_cmatrix,
`XGBoost` = smote_xgb_cmatrix,
`Single Neural Net` = smote_single_nn_cmatrix,
`2 layer Neural Net` = smote_two_nn_cmatrix,
`Deep Neural Net` = smote_deep_nn_cmatrix
)
tomek_confusionmatrices <- list(
`Logistic Regression` = tomek_log_cmatrix,
`QDA` = tomek_qda_cmatrix,
`LDA` = tomek_lda_cmatrix,
`KNN` = tomek_knn_cmatrix,
`Random Forest` = tomek_rf_cmatrix,
`Naive Bayes` = tomek_nb_cmatrix,
`GBM` = tomek_gbm_cmatrix,
`XGBoost` = tomek_xgb_cmatrix,
`Single Neural Net` = tomek_single_nn_cmatrix,
`2 layer Neural Net` = tomek_two_nn_cmatrix,
`Deep Neural Net` = tomek_deep_nn_cmatrix
)
algo_confusionmatrices <- list(
`Near Miss` = nearmiss_confusionmatrices,
`SMOTE` = smote_confusionmatrices,
`Tomek Links` = tomek_confusionmatrices
)
all_tables <- list()
tables <- list()
for (algo_name in names(algo_confusionmatrices)){
confusionmatrices <- algo_confusionmatrices[[algo_name]]
metrics_list <- list()
# Ensure that you loop over the names of confusionmatrices, not predictions
for (model_name in names(confusionmatrices)) {
cm <- confusionmatrices[[model_name]]
metrics_list[[model_name]] <- cm$byClass
}
metrics_df <- do.call(cbind, metrics_list)
comparison_table <- t(metrics_df)
all_tables[[algo_name]] <- data.frame(comparison_table)
comparison_table <- comparison_table %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Model") %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced Accuracy`, Sensitivity) %>%
dplyr::arrange(desc(F1))
tables[[algo_name]] <-  data.frame(comparison_table)
}
all_tables[["Near Miss"]]
all_tables[["SMOTE"]]
all_tables[["Tomek Links"]]
#results:
#f1,
tables[["Near Miss"]]
tables[["Near Miss"]]
tables[["SMOTE"]]
tables[["Tomek Links"]]
tables[["Near Miss"]]
tables[["SMOTE"]]
tables[["Tomek Links"]]
#Logistic Regression, QDA, LDA, KNN, Random Forest, Linear SVM, Poly SVM, Radial SVM, Naive Bayes, GBM, XGBoost, Single Neural Net, 2 layer Neural Net, Deep Neural Net
#nearmiss_confusionmatrices[[""]]
#Logistic Regression, QDA, LDA, Random Forest, Naive Bayes, GBM, XGBoost, Single Neural Net, 2 layer Neural Net, Deep Neural Net
#smote_confusionmatrices[[""]]
#Logistic Regression, QDA, LDA, KNN, Random Forest, Naive Bayes, GBM, XGBoost, Single Neural Net, 2 layer Neural Net, Deep Neural Net
tomek_confusionmatrices[["Random Forest"]]
#all metrics: (Method = "Near Miss", "SMOTE", "Tomek Links")
all_tables[["Near Miss"]]
comparison_table <- comparison_table %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Model")
actual <- test_data$Class
nearmiss_confusionmatrices <- list(
`Logistic Regression` = nearmiss_log_cmatrix,
`QDA` = nearmiss_qda_cmatrix,
`LDA` = nearmiss_lda_cmatrix,
`KNN` = nearmiss_knn_cmatrix,
`Random Forest` = nearmiss_rf_cmatrix,
`Linear SVM` = nearmiss_linear_svm_cmatrix,
`Poly SVM` = nearmiss_poly_svm_cmatrix,
`Radial SVM` = nearmiss_radial_svm_cmatrix,
`Naive Bayes` = nearmiss_nb_cmatrix,
`GBM` = nearmiss_gbm_cmatrix,
`XGBoost` = nearmiss_xgb_cmatrix,
`Single Neural Net` = nearmiss_single_nn_cmatrix,
`2 layer Neural Net` = nearmiss_two_nn_cmatrix,
`Deep Neural Net` = nearmiss_deep_nn_cmatrix
)
smote_confusionmatrices <- list(
`Logistic Regression` = smote_log_cmatrix,
`QDA` = smote_qda_cmatrix,
`LDA` = smote_lda_cmatrix,
`Random Forest` = smote_rf_cmatrix,
`Naive Bayes` = smote_nb_cmatrix,
`GBM` = smote_gbm_cmatrix,
`XGBoost` = smote_xgb_cmatrix,
`Single Neural Net` = smote_single_nn_cmatrix,
`2 layer Neural Net` = smote_two_nn_cmatrix,
`Deep Neural Net` = smote_deep_nn_cmatrix
)
tomek_confusionmatrices <- list(
`Logistic Regression` = tomek_log_cmatrix,
`QDA` = tomek_qda_cmatrix,
`LDA` = tomek_lda_cmatrix,
`KNN` = tomek_knn_cmatrix,
`Random Forest` = tomek_rf_cmatrix,
`Naive Bayes` = tomek_nb_cmatrix,
`GBM` = tomek_gbm_cmatrix,
`XGBoost` = tomek_xgb_cmatrix,
`Single Neural Net` = tomek_single_nn_cmatrix,
`2 layer Neural Net` = tomek_two_nn_cmatrix,
`Deep Neural Net` = tomek_deep_nn_cmatrix
)
algo_confusionmatrices <- list(
`Near Miss` = nearmiss_confusionmatrices,
`SMOTE` = smote_confusionmatrices,
`Tomek Links` = tomek_confusionmatrices
)
all_models <- list()
for (algo_name in names(algo_confusionmatrices)){
confusionmatrices <- algo_confusionmatrices[[algo_name]]
metrics_list <- list()
# Ensure that you loop over the names of confusionmatrices, not predictions
for (model_name in names(confusionmatrices)) {
cm <- confusionmatrices[[model_name]]
metrics_list[[model_name]] <- cm$byClass
}
metrics_df <- do.call(cbind, metrics_list)
comparison_table <- t(metrics_df)
comparison_table <- comparison_table %>%
as.data.frame() %>%
tibble::rownames_to_column(var = "Model") %>%
dplyr::mutate(Method = algo_name)
all_models[[algo_name]] <-  data.frame(comparison_table)
}
all_models <- do.call(rbind, all_models)
all_models
all_models%>%
dplyr::select(Model, F1, Precision, Recall, `Balanced Accuracy`, Sensitivity) %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced Accuracy`, Sensitivity) %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity) %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method) %>%
dplyr::arrange(desc(F1))
row.names(all_models) <- NULL
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method) %>%
dplyr::filter(Method = "Near Miss") %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method) %>%
dplyr::filter(Method == "Near Miss") %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method) %>%
dplyr::filter(Method == "Tomek Links") %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method) %>%
dplyr::filter(Method == "Tomek Links") %>%
dplyr::arrange(desc(F1))
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method)
dplyr::arrange(desc(F1)) %>%
head()
all_models %>%
dplyr::select(Model, F1, Precision, Recall, `Balanced.Accuracy`, Sensitivity, Method) %>%
dplyr::arrange(desc(F1)) %>%
top_n(n=10)
#Individual Confusion Matrices:
#Logistic Regression, QDA, LDA, KNN, Random Forest, Linear SVM, Poly SVM, Radial SVM, Naive Bayes, GBM, XGBoost, Single Neural Net, 2 layer Neural Net, Deep Neural Net
#nearmiss_confusionmatrices[[""]]
#Logistic Regression, QDA, LDA, Random Forest, Naive Bayes, GBM, XGBoost, Single Neural Net, 2 layer Neural Net, Deep Neural Net
#smote_confusionmatrices[[""]]
#Logistic Regression, QDA, LDA, KNN, Random Forest, Naive Bayes, GBM, XGBoost, Single Neural Net, 2 layer Neural Net, Deep Neural Net
tomek_confusionmatrices[["XGBoost"]]
